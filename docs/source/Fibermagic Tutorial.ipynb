{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6b04878",
   "metadata": {},
   "source": [
    "# Fibermagic Tutorial\n",
    "\n",
    "Fibermagic is an open-source software package for the analysis of photometry data. It is written in Python and operates on pandas and numpy dataframes.\n",
    "\n",
    "Fiber Photometry is a novel technique to capture neural activity in-vivo with a subsecond temporal precision. Genetically encoded fluorescent sensors are expressed by either transfection with an (AAV)-virus or transgenic expression. Strenght of fluorescence is dependent on the concentration of the neurotransmitter the sensor detects. Using an optic glas fiber, it is possible to image neural dynamics and transmitter release.\n",
    "\n",
    "![FP image](https://upload.wikimedia.org/wikipedia/commons/e/eb/Fiber_Pho.png)\n",
    "\n",
    "graphik source: https://en.wikipedia.org/wiki/Fiber_photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b4da21",
   "metadata": {},
   "source": [
    "## Fiber Photometry using Neurophotometrics devices\n",
    "\n",
    "There are a bunch of different photometry systems out there like TDT systems, Neurophotometrics or open-hardware approaches. In this tutorial, we will use data from Neurophotometrics as an example.\n",
    "\n",
    "![NPM](npm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce5455f",
   "metadata": {},
   "source": [
    "## Multiple Colors\n",
    "\n",
    "With Neurophotometrics (NPM), it is possible to capture data from two fluorescent sensors simultaneously - if they emit light in different wave lengths. NPM can measure light of two different color spectra: Red and Green. Using this technology, it is possible, to e.g. express a green calcium sensor (e.g. GCaMP6f) and a red dopamine sensor (e.g. Rdlight1).\n",
    "\n",
    "![Multiple Colors](https://www.researchgate.net/profile/Yongxin-Zhao-3/publication/264796291/figure/fig3/AS:272756524711981@1442041631582/Spectral-overlap-of-fluorescent-proteins-with-QuasAr2-absorption-a-eFRET-GEVI-domain.png)\n",
    "grafik source: https://www.researchgate.net/publication/264796291_Bright_and_fast_multi-colored_voltage_reporters_via_electrochromic_FRET/figures?lo=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddceae2",
   "metadata": {},
   "source": [
    "## Multiple Mice\n",
    "\n",
    "NPM can record data from multiple mice at once - delivered through a single path chord that splits into several small cables that can be attached individually to a single mouse.\n",
    "\n",
    "The end of the patch chord projects to a photosensor which captures the light. Here's how it looks like:\n",
    "\n",
    "![Multiple Mice](multiple_mice.png)\n",
    "\n",
    "Before starting the recording, the researcher defines a region of interest for each cable and color. Then, NPM captures the light intensity for each region of interest seperately. All data streams are written into one single csv file per recording."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31919e23",
   "metadata": {},
   "source": [
    "## Investigating a single raw data file\n",
    "\n",
    "Let's have a look into an arbitrary recording file and try to understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef9faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fibermagic\n",
    "import pandas as pd\n",
    "from fibermagic.utils.download_dataset import download\n",
    "download('tutorial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed111e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('rawdata_demo.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7038cc9e",
   "metadata": {},
   "source": [
    "Each Region of Interest is represented as one column. \n",
    "\n",
    "A simple frame counter and a timestamp indicate when a measurement happened.\n",
    "\n",
    "The Flags column encodes different things: Which LED was on at the time of measurement, which input and/or output channel was on or off and whether the laser for optogenetic stimulation was on. NPM encodes all this information into a single number using a dual encoding.\n",
    "\n",
    "Because the emission spectra of fluorescent proteins are partly overlapping, it is not possible to measure both, the red and green sensor, at the same time. Instead, only one LED is on at a time. That way, we get presice measurements.\n",
    "\n",
    "![rawdata](raw_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89713fb4",
   "metadata": {},
   "source": [
    "We can use fibermagic to decode which LEDs were on at what measurement from the Flags column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c888811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fibermagic.IO.NeurophotometricsIO import extract_leds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4f7292",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Flags' in df.columns:  # legacy fix: Flags were renamed to LedState\n",
    "    df = df.rename(columns={'Flags': 'LedState'})\n",
    "df = extract_leds(df).dropna()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea77ff8",
   "metadata": {},
   "source": [
    "Now, we have all we need to plot the full trace of a single sensor of one mouse and inspect the raw data values. In this recording, Rdlight1 and GCaMP6f were expressed. Rdlight1 is excited by the 560 nm LED and emits light in the red color spectrum. GCaMP6f is excited by the 470 nm LED and emits light in the green spectrum. Now, let's spike into the raw data of Rdlight1 of a single mouse.\n",
    "\n",
    "We use \"plotly\" for plotting here. Plotly is a plotting library for Python and other programming languages. It is interactive, which means we can zoom in and out and scroll through the data, which is exactly what we want to do at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226e5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc973a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "region0R_red = df[df.wave_len == 560][['FrameCounter', 'Region0R']]\n",
    "px.line(region0R_red, x='FrameCounter', y='Region0R')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecefbe2",
   "metadata": {},
   "source": [
    "We can clearly see huge transients from dopamine activity in the raw data. Congratulations!\n",
    "\n",
    "However, there are several issues with the data. Fiber Photometry is not measureing the difference between day and night. Changes in fluorescence are usually extremely small and very hard to measure. We basically measure light intensity with a super high precision. However, this means that the photometry system will also pick up every disturbance, even if very small.\n",
    "\n",
    "Examples of unwanted noise are:\n",
    "* Photobleaching of the Patch Chord\n",
    "* Photobleaching caused by LED heating\n",
    "* Photobleaching caused by destroyment of sensors\n",
    "* Motion artifacts\n",
    "* Loose or poorly attached cables\n",
    "\n",
    "![photobleaching](photobleaching.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f424e92d",
   "metadata": {},
   "source": [
    "## Demodulation of Fiber Photometry Data\n",
    "\n",
    "As we saw, the raw data is useless without further processing. There are a variety of different of different methods to remove photobleaching and motion artifacts, here are a few examples:\n",
    "\n",
    "### Correction of Photobleaching:\n",
    "\n",
    "* High-Pass Filtering: Photobleaching usually occurs at a very slow timescale. By applying a simple high-pass filter, e.g. a butterworth, it is possible to remove the gross artifacts of photobleaching, but it removes also slow changes in neurotransmitter concentration\n",
    "* Biexponential decay: Photobleaching can be estimated by a decreasing exponential function. However, as it happens on two different timescales (e.g. fast LED-heating-based photobleaching and slow patch chord photobleaching), we need a biexponential decay that can be regressed to the data and then subtracted.\n",
    "* airPLS: Adaptive iteratively reweighted penalized least squares. A more advanced method to remove artifacts. For more info, please see the paper: DOI: 10.1039/b922045c\n",
    "\n",
    "### Correction of Motion Artifacts:\n",
    "\n",
    "* Genetically encoded Neurotransmitter indicators have usually a useful attribute: If stimulated at around 410 nm (instead of e.g. 470 or 560), the excitation will be the same independent of the neurotransmitter concentration. Stimulating a this wave length is called recording an \"isobestic\". The isobestic is usefull to correct motion artifacts.\n",
    "* If a transient is caused by neural activity, it should be detectable in the signal channel, but if it is caused by motion, it should be detectable in both, the isobestic and signal.\n",
    "* We can remove motion artifacts if we fit the isobestic to the signal and subtract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0a33a",
   "metadata": {},
   "source": [
    "## Demodulate using airPLS\n",
    "\n",
    "We can use fibermagic to calculate z-scores of dF/F using the airPLS algorithm. However, before we do that, we need to bring the dataframe into long-format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e798c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "NPM_RED = 560\n",
    "NPM_GREEN = 470\n",
    "NPM_ISO = 410\n",
    "# dirty hack to come around dropped frames until we find better solution -\n",
    "# it makes about 0.16 s difference\n",
    "df.FrameCounter = df.index // len(df.wave_len.unique())\n",
    "df = df.set_index('FrameCounter')\n",
    "regions = [column for column in df.columns if 'Region' in column]\n",
    "dfs = list()\n",
    "for region in regions:\n",
    "    channel = NPM_GREEN if 'G' in region else NPM_RED\n",
    "    sdf = pd.DataFrame(data={\n",
    "        'Region': region,\n",
    "        'Channel': channel,\n",
    "        'Signal': df[region][df.wave_len == channel],\n",
    "        'Reference': df[region][df.wave_len == NPM_ISO]\n",
    "    }\n",
    "    )\n",
    "    dfs.append(sdf)\n",
    "dfs = pd.concat(dfs).reset_index().set_index(['Region', 'Channel', 'FrameCounter'])\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fibermagic.core.demodulate import add_zdFF\n",
    "\n",
    "dfs = add_zdFF(dfs, method='airPLS', remove=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991caa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3406dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(dfs.reset_index(), x='FrameCounter', y='zdFF (airPLS)', facet_row='Region', height=1000)\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c21b7b9",
   "metadata": {},
   "source": [
    "## Analyzing and Synchronizing Behavioral Data\n",
    "\n",
    "In almost all experiments, we want to collect behavioral data along with the neural data. We then want to correlate the mice's behavior with our neural recording. For example, the mouse might perform a lever pressing task in an operand box. The operand box collects data about the time when the lever is pressed and when a food reward is delivered.\n",
    "\n",
    "Let's have a look into the log file produced by the operant box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e255c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = pd.read_csv('operand_box.log')\n",
    "logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f114aaa9",
   "metadata": {},
   "source": [
    "As we see, the column \"SI@0.0\" records the type of event (e.g. left lever pressed; food delivered, etc...) and the time.\n",
    "\n",
    "There are a variety of possibilities how to synchronize the logs with the FP data. In this case, an external generator generates a TTL pulse every 100 ms. The TTL pulse is captured by the operand box and logged as SI. The TTL pulse is also captured by the \"input1\" channel of NPM and saved in \"input1.csv\".\n",
    "\n",
    "Luckily, fibermagic offers functionality to synchronize both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0984589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fibermagic.IO.NeurophotometricsIO import sync_from_TTL_gen\n",
    "from pathlib import Path\n",
    "\n",
    "logs = sync_from_TTL_gen(logs, Path('.'))\n",
    "logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134dc429",
   "metadata": {},
   "source": [
    "We see that the column 'FrameCounter' was added to the dataframe. Now we know exactly where in the photometry data an event happened.\n",
    "\n",
    "## Plot Perievents\n",
    "\n",
    "With the synchronization done, we can finally extract a few seconds before and after each event and investigate if there is a common pattern. This is called calculating perievents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs['Region'] = 'Region6R'\n",
    "logs = logs.set_index('Region', append=True).swaplevel()\n",
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947373a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fibermagic.core.perievents import perievents\n",
    "\n",
    "peri = perievents(dfs.set_index('FrameCounter', append=True), logs[logs.Event=='FD'], window=5, frequency=25)\n",
    "peri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564cbc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(peri.reset_index(), x='Timestamp', y='Trial', color='zdFF (airPLS)', range_color=(-5,5),\n",
    "                 color_continuous_scale=['blue', 'grey', 'red'], height=250).update_yaxes(autorange=\"reversed\")\n",
    "for scatter in fig.data:\n",
    "    scatter.marker.symbol = 'square'\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38c143",
   "metadata": {},
   "source": [
    "# How to analyze big projects\n",
    "\n",
    "So far, we analyzed one single mouse, one single recording, one single channel. However, in practice, we usually record from 10-20 mice per experiment and have multiple long recordings. This adds up easily to several hundret files together with all the logs produced. It would be very time consuming and error-prone if a researcher would have to analyze every single file on its own.\n",
    "\n",
    "Fortunately, fibermagic offers functionality to process a full project at once and fully automatically. In addition, fibermagic is very fast and can process full projects within seconds. Ultimately, you can use the same functions, no matter if you load a full project or a single file.\n",
    "\n",
    "The only thing you have to do is to structure your project into a tree of directories with one category per level. For example, you may want to structure your project into experimental group (condition/control), experimental procedure (e.g. PR2, PR5, PR8, PR11) and recording (e.g. R1, R2, R3). You have to organize your recordings into subdirectories.\n",
    "```\n",
    "== condition\n",
    "      =PR2\n",
    "          =R1\n",
    "               data.csv\n",
    "               input1.csv\n",
    "               regions_to_mouse.csv\n",
    "               time.csv\n",
    "               logs.csv\n",
    "          =R2\n",
    "          =R3\n",
    "      =PR5\n",
    "      =PR8\n",
    "      =PR11\n",
    " = control\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fibermagic.IO.NeurophotometricsIO import read_project_logs, read_project_rawdata\n",
    "\n",
    "download('fdrd2xadora_PR_Pilot')\n",
    "help(read_project_rawdata)\n",
    "help(read_project_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad27b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = Path(r'fdrd2xadora_PR_Pilot')\n",
    "logs = read_project_logs(project_path,\n",
    "                                 ['Paradigm'], ignore_dirs=['meta', 'processed'])\n",
    "df = read_project_rawdata(project_path,\n",
    "                          ['Paradigm'], 'FED3.csv', ignore_dirs=['meta', 'processed'])\n",
    "df = add_zdFF(df, smooth_win=10, remove=200).set_index('FrameCounter', append=True)\n",
    "peri = perievents(df, logs[logs.Event == 'FD'], 5, 25)\n",
    "output_path = project_path / 'processed'\n",
    "df.to_csv(output_path / 'datastream.csv')\n",
    "logs.to_csv(output_path / 'logs.csv')\n",
    "peri.to_csv(output_path / 'perievents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "peri = peri.reset_index()\n",
    "fig = px.scatter(peri[peri.Channel==560], x='Timestamp', y='Trial', color='zdFF (airPLS)', facet_row='Paradigm', facet_col='Mouse',\n",
    "          range_color=(-5,5), facet_row_spacing=0, facet_col_spacing=0, width=140*len(peri.Mouse.unique()),\n",
    "                 color_continuous_scale=['blue', 'grey', 'red']).update_yaxes(autorange=\"reversed\")\n",
    "for scatter in fig.data:\n",
    "    scatter.marker.symbol = 'square'\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    "fig.update_xaxes(range = [peri.Timestamp.min(),peri.Timestamp.max()])\n",
    "fig.update_xaxes(matches='x')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa4669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "peri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d93b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}